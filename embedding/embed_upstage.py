import os
import json
import glob
import hashlib
import requests
from tqdm import tqdm
from dotenv import load_dotenv

# ---------------------------
# 0. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.env)
# ---------------------------
load_dotenv()
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
UPSTAGE_EMBED_URL = "https://api.upstage.ai/v1/embeddings"

# ---------------------------
# 1. Upstage ì„ë² ë”© í•¨ìˆ˜
# ---------------------------
def get_embedding(text: str, mode: str = "passage"):
    """
    mode: "passage" (ë¬¸ì„œ ì €ì¥ìš©) or "query" (ê²€ìƒ‰ìš©)
    """
    headers = {
        "Authorization": f"Bearer {UPSTAGE_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": f"solar-embedding-1-large-{mode}",  # passage / query êµ¬ë¶„
        "input": [text]
    }
    resp = requests.post(UPSTAGE_EMBED_URL, json=payload, headers=headers, timeout=60)
    resp.raise_for_status()
    data = resp.json()
    return data["data"][0]["embedding"]

# ë³„ë„ wrapper í•¨ìˆ˜ (ê°€ë…ì„±ìš©)
def embed_passage(text: str):
    return get_embedding(text, mode="passage")

def embed_query(text: str):
    return get_embedding(text, mode="query")

# ---------------------------
# 2. JSON ë°ì´í„° ì²˜ë¦¬ â†’ ë¡œì»¬ ì €ì¥
# ---------------------------
def process_json_file(file_path, category, save_file):
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    embeddings = []
    for i, item in enumerate(data):
        if "ì§ˆë¬¸" in item and "ë‹µë³€" in item:
            task = "QA"
            question = item.get("ì§ˆë¬¸", "")
            answer = item.get("ë‹µë³€", "")
            content, summary = None, None
            text_to_embed = f"[ì§ˆë¬¸] {question}\n[ë‹µë³€] {answer}"
        elif "ë³¸ë¬¸" in item and "ìš”ì•½" in item:
            task = "SUMMARY"
            question, answer = None, None
            content = item.get("ë³¸ë¬¸", "")
            summary = item.get("ìš”ì•½", "")
            text_to_embed = f"[ë³¸ë¬¸] {content}\n[ìš”ì•½] {summary}"
        else:
            continue

        # passage ì„ë² ë”©
        embedding = embed_passage(text_to_embed)

        uid = hashlib.md5(f"{file_path}_{i}".encode()).hexdigest()

        embeddings.append({
            "id": uid,
            "vector": embedding,
            "metadata": {
                "category": category,
                "task": task,
                "question": question,
                "answer": answer,
                "content": content,
                "summary": summary,
                "file": os.path.basename(file_path)
            }
        })

    if embeddings:
        with open(save_file, "a", encoding="utf-8") as f:
            for e in embeddings:
                f.write(json.dumps(e, ensure_ascii=False) + "\n")
        print(f"âœ… {file_path} â†’ {len(embeddings)}ê°œ ë¡œì»¬ ì €ì¥ ì™„ë£Œ ({category})")

# ---------------------------
# 3. ì‹¤í–‰ (ì„ë² ë”© ì €ì¥)
# ---------------------------
BASE_DIR = "/mnt/c/Users/Admin/Downloads/dataset"
DATASETS = {
    "legal": os.path.join(BASE_DIR, "ip_legal_data/train/labeled/**/*.json"),
    "patent": os.path.join(BASE_DIR, "patent_data/train/raw/kr*.json")
}

if __name__ == "__main__":
    for category, path_pattern in DATASETS.items():
        files = glob.glob(path_pattern, recursive=True)
        for file in tqdm(files, desc=f"{category}"):
            process_json_file(file, category, save_file=f"{category}_embeddings.json")

    # ---------------------------
    # 4. ê²€ìƒ‰ ì˜ˆì‹œ (query)
    # ---------------------------
    sample_question = "íŠ¹í—ˆ ì¶œì›ì¼ì´ ì–¸ì œì¸ê°€ìš”?"
    q_vec = embed_query(sample_question)
    print(f"\nğŸ” Query Example: {sample_question}")
    print(f"ì„ë² ë”© ì°¨ì›: {len(q_vec)} (expected 1024)")
    print(f"ì• 5ê°œ ê°’: {q_vec[:5]}")
