import os
import json
import glob
import hashlib
import requests
from tqdm import tqdm
from dotenv import load_dotenv

# ---------------------------
# 0. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.env)
# ---------------------------
load_dotenv()
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
UPSTAGE_EMBED_URL = "https://api.upstage.ai/v1/embeddings"

# ---------------------------
# 1. Upstage ì„ë² ë”© í•¨ìˆ˜
# ---------------------------
def get_embedding(text: str, mode: str = "passage"):
    """
    mode: "passage" (ë¬¸ì„œ ì €ì¥ìš©) or "query" (ê²€ìƒ‰ìš©)
    """
    headers = {
        "Authorization": f"Bearer {UPSTAGE_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": f"solar-embedding-1-large-{mode}",  # passage / query êµ¬ë¶„
        "input": [text]
    }
    resp = requests.post(UPSTAGE_EMBED_URL, json=payload, headers=headers, timeout=60)
    resp.raise_for_status()
    data = resp.json()
    return data["data"][0]["embedding"]

# Wrapper í•¨ìˆ˜
def embed_passage(text: str):
    return get_embedding(text, mode="passage")

def embed_query(text: str):
    return get_embedding(text, mode="query")

# ---------------------------
# 2-1) ë ˆì½”ë“œ ë¹Œë”: ë²•ë¥  ë°ì´í„°
# ---------------------------
def build_legal_record(item: dict):
    # ì¼€ì´ìŠ¤ 1: title + output êµ¬ì¡°
    title = item.get("title", "")
    output = item.get("output", "")
    if title or output:
        text = f"[ì œëª©] {title}\n[ìš”ì•½] {output}"
        task = "LEGAL_SUMMARY"

    # ì¼€ì´ìŠ¤ 2: ì§ˆë¬¸/ë‹µë³€ êµ¬ì¡°
    elif "ì§ˆë¬¸" in item and "ë‹µë³€" in item:
        text = f"[ì§ˆë¬¸] {item.get('ì§ˆë¬¸','')}\n[ë‹µë³€] {item.get('ë‹µë³€','')}"
        task = "LEGAL_QA"

    # ì¼€ì´ìŠ¤ 3: ë³¸ë¬¸/ìš”ì•½ êµ¬ì¡°
    elif "ë³¸ë¬¸" in item and "ìš”ì•½" in item:
        text = f"[ë³¸ë¬¸] {item.get('ë³¸ë¬¸','')}\n[ìš”ì•½] {item.get('ìš”ì•½','')}"
        task = "LEGAL_SUMMARY"
    else:
        return None

    meta = {
        "category": "legal",
        "task": task,
        "response_institute": item.get("response_institute"),
        "response_date": item.get("response_date"),
        "title": title or item.get("title"),
        "sentences": item.get("sentences"),
        "file_section": item.get("section"),
    }
    return text, meta

# ---------------------------
# 2-2) ë ˆì½”ë“œ ë¹Œë”: íŠ¹í—ˆ ë°ì´í„°
# ---------------------------
def build_patent_record(item: dict):
    inv = item.get("invention_title", "") or item.get("title", "")
    abstract = item.get("abstract", "")
    kw = item.get("keyword", [])
    if isinstance(kw, list):
        kw_str = ", ".join(map(str, kw))
    else:
        kw_str = str(kw) if kw else ""

    if inv or abstract or kw_str:
        text = f"[ë°œëª…ì˜ëª…ì¹­] {inv}\n[ìš”ì•½] {abstract}\n[ì£¼ìš”í‚¤ì›Œë“œ] {kw_str}"
        task = "PATENT_ABS"
    else:
        return None

    claims = item.get("claims")
    if isinstance(claims, list):
        claims = "\n".join(map(str, claims))

    meta = {
        "category": "patent",
        "task": task,
        "register_date": item.get("register_date"),
        "open_date": item.get("open_date"),
        "application_date": item.get("application_date"),
        "documentId": item.get("documentId") or item.get("document_id"),
        "title": item.get("title") or inv,
        "claims": claims,
    }
    return text, meta

# ---------------------------
# 3. JSON ë°ì´í„° ì²˜ë¦¬ â†’ ë¡œì»¬ ì €ì¥
# ---------------------------
def process_json_file(file_path, category, save_file):
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    embeddings = []
    for i, item in enumerate(data):
        if not isinstance(item, dict):   # âœ… dict ì•„ë‹Œ ê±´ ìŠ¤í‚µ
            continue

        if category == "legal":
            built = build_legal_record(item)
        else:  # "patent"
            built = build_patent_record(item)

        if not built:
            continue

        text_to_embed, metadata = built
        emb = embed_passage(text_to_embed)   # passage ì„ë² ë”©
        uid = hashlib.md5(f"{file_path}_{i}".encode()).hexdigest()

        embeddings.append({
            "id": uid,
            "vector": emb,
            "metadata": {**metadata, "file": os.path.basename(file_path)}
        })

    if embeddings:
        with open(save_file, "a", encoding="utf-8") as f:
            for e in embeddings:
                f.write(json.dumps(e, ensure_ascii=False) + "\n")
        print(f"âœ… {file_path} â†’ {len(embeddings)}ê°œ ë¡œì»¬ ì €ì¥ ì™„ë£Œ ({category})")

# ---------------------------
# 4. ì‹¤í–‰
# ---------------------------
BASE_DIR = "/mnt/c/Users/Admin/Downloads/dataset"
DATASETS = {
    "legal": os.path.join(BASE_DIR, "ip_legal_data/train/labeled/**/*.json"),
    "patent": os.path.join(BASE_DIR, "patent_data/train/raw/kr*.json")
}

if __name__ == "__main__":
    for category, path_pattern in DATASETS.items():
        files = glob.glob(path_pattern, recursive=True)
        for file in tqdm(files, desc=f"{category}"):
            process_json_file(file, category, save_file=f"{category}_embeddings.json")

    # ---------------------------
    # 5. ê²€ìƒ‰ ì˜ˆì‹œ (query)
    # ---------------------------
    sample_question = "íŠ¹í—ˆ ì¶œì›ì¼ì´ ì–¸ì œì¸ê°€ìš”?"
    q_vec = embed_query(sample_question)
    print(f"\nğŸ” Query Example: {sample_question}")
    print(f"ì„ë² ë”© ì°¨ì›: {len(q_vec)} (expected 1024)")
    print(f"ì• 5ê°œ ê°’: {q_vec[:5]}")
